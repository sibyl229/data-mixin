** required library
numpy
scipy
** likely needed library
biopython	# if computing features from Fasta files
matplotlib	# for plotting
scikit-learn 	# for machine learning
PyBrain		# for neural network

if you have pip setup, all packages can be installed with:
pip install package_name



** How to use it
- Get a copy of the raw_inputs/ directory and place it in the project root directory
- create a directory called input/ at the project root
- run compute_data.py to generate feature score files
- run DataRemap.py to take features scores for a selected list of proteins
- run linear.py to combine and normalize feature scores for the selected proteins, and run learning algorithm


** Purpose of each files and directories (refer to those python modules for more detailed documentations)
input/	      	   	 Standardized (!!!) feature scores for selected proteins (generated by DataRemap.py)
raw_inputs/   	   	 ALL data gathered, AND feature scores computed from those data
DataRemap.py		 Standardize feature scores: take the same list of proteins as template and fill in feature scores for them	 
data.py			 Deal with reading various types of feature files, used by DataRemap.py to access the data
compute_data.py		 Deal with computing various features from raw data, used by DataRemap.py to access the data
linear.py		 Combine various standardized features for learning, normalize the features, and try applying some learning algorithms		 


** How to add new features
- put feature data in raw_inputs/ directory
- if the feature score already is in csv/tsv file, where each row is identified by Uniprot id, extend the AbstractData class (refer to data.py)
- otherwise, extend the AbstractComputedData class (refer to compute_data.py), AND edit main() in compute_data.py to instantiate the new class (which computes scores for the feature)
- edit the main() in DataRemap.py to include this class
- run compute_data.py (if applicable), then DataRemap.py, and then linear.py
